# -*- coding: utf-8 -*-
"""ModelComparison_BiomeSuitability.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10zkyu5HhKjdDA81o7D-STeQ3ejYMGjMK

# Before tuning

```
# This is formatted as code
```

## Matrix comparison
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load the exported matrices
xgb = pd.read_csv("b4tuning/xgb_matrix.csv", index_col=0)
rf = pd.read_csv("b4tuning/rf_matrix.csv", index_col=0)
logreg = pd.read_csv("b4tuning/logreg_matrix.csv", index_col=0)
knn = pd.read_csv("b4tuning/knn_matrix.csv", index_col=0)

# Melt and merge for plotting
xgb["Model"] = "XGBoost"
rf["Model"] = "Random Forest"
logreg["Model"] = "Logistic Regression"
knn["Model"] = "KNN"


# Ensure index (species) is reset before melting
for df in [xgb, rf, logreg, knn]:
    df.reset_index(inplace=True)
all_data = pd.concat([xgb, rf, logreg, knn])
all_data = all_data.rename(columns={"index": "Species"})
melted = all_data.melt(id_vars=["Species", "Model"], var_name="Biome", value_name="Score")

# Plot comparison heatmap or barplot
plt.figure(figsize=(14, 6))
sns.barplot(data=melted, x="Biome", y="Score", hue="Model", errorbar=None)
plt.title("Average Suitability per Biome (by Model)")
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()

# Pivot melted data to species-biome-model format
pivoted = melted.pivot_table(index=["Species", "Biome"], columns="Model", values="Score")
correlation = pivoted.dropna().corr()

print(pivoted.isna().sum())

print(pivoted.std())

# Plot correlation between models
plt.figure(figsize=(6, 5))
sns.heatmap(correlation, annot=True, cmap="coolwarm", center=0.5)
plt.title("Correlation Between Models' Compatibility Scores")
plt.tight_layout()
plt.show()

"""## Metric Comparison"""

rf_metrics = pd.read_csv("b4tuning/rf_metrics.csv")
xgb_metrics = pd.read_csv("b4tuning/xgb_metrics.csv")
logreg_metrics = pd.read_csv("b4tuning/logreg_metrics.csv")
knn_metrics = pd.read_csv("b4tuning/knn_metrics.csv")

# Combine
all_metrics = pd.concat([rf_metrics, xgb_metrics, logreg_metrics, knn_metrics])
all_metrics.head()

plt.figure(figsize=(10, 6))
sns.boxplot(data=all_metrics, x="Model", y="F1")
plt.title("F1 Score Distribution per Model")
plt.show()

plt.figure(figsize=(14, 6))
sns.barplot(data=all_metrics, x="Species", y="Accuracy", hue="Model", errorbar=None)
plt.title("Accuracy per Species by Model")
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()

summary = all_metrics.groupby("Model")[["Accuracy", "Precision", "Recall", "F1"]].mean().round(3)
summary = summary.sort_values("F1", ascending=False)
display(summary)

"""# After tuning

## Matrix Comparison
"""

# Load the exported matrices
rf_metrics_tuned = pd.read_csv("tuned/rf_tuned_metrics.csv", index_col=0)
xgb_metrics_tuned = pd.read_csv("tuned/xgb_tuned_metrics.csv", index_col=0)
logreg_metrics_tuned = pd.read_csv("tuned/logreg_tuned_metrics.csv", index_col=0)
knn_metrics_tuned = pd.read_csv("tuned/knn_tuned_metrics.csv", index_col=0)

# Add model labels before stacking
xgb["Model"] = "XGBoost Tuned"
rf["Model"] = "Random Forest Tuned"
logreg["Model"] = "Logistic Regression Tuned"
knn["Model"] = "KNN Tuned"

# Drop 'level_0' if it exists
for df in [xgb, rf, logreg, knn]:
    df.drop(columns=["level_0"], errors="ignore", inplace=True)

# Combine all matrices
all_data = pd.concat([xgb, rf, logreg, knn])

# Melt, keeping 'Model' and biome name intact
melted = all_data.reset_index().melt(id_vars=["index", "Model"], var_name="Biome", value_name="Score")
melted = melted.rename(columns={"index": "Species"})  # Optional but cleaner

# Drop unwanted 'level_0' rows from Biome column
melted = melted[melted["Biome"] != "level_0"]

# Plot
plt.figure(figsize=(14, 6))
sns.barplot(data=melted, x="Biome", y="Score", hue="Model", errorbar=None)
plt.title("Average Suitability per Biome (by Model, Tuned)")
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()

# Pivot melted data to species-biome-model format
pivoted = melted.pivot_table(index=["Species", "Biome"], columns="Model", values="Score")
correlation = pivoted.dropna().corr()

print(pivoted.isna().sum())

print(pivoted.std())

# Plot correlation between models
plt.figure(figsize=(6, 5))
sns.heatmap(correlation, annot=True, cmap="coolwarm", center=0.5)
plt.title("Correlation Between Models' Compatibility Scores")
plt.tight_layout()
plt.show()

"""## Metric Comparison"""

rf_metrics_tuned = pd.read_csv("tuned/rf_tuned_metrics.csv")
xgb_metrics_tuned = pd.read_csv("tuned/xgb_tuned_metrics.csv")
logreg_metrics_tuned = pd.read_csv("tuned/logreg_tuned_metrics.csv")
knn_metrics_tuned = pd.read_csv("tuned/knn_tuned_metrics.csv")

# Combine
all_metrics_tuned = pd.concat([rf_metrics_tuned, xgb_metrics_tuned,
                               logreg_metrics_tuned, knn_metrics_tuned])
all_metrics_tuned.head()

plt.figure(figsize=(10, 6))
sns.boxplot(data=all_metrics_tuned, x="Model", y="F1")
plt.title("F1 Score Distribution per Model")
plt.show()

plt.figure(figsize=(14, 6))
sns.barplot(data=all_metrics_tuned, x="Species", y="Accuracy", hue="Model", errorbar=None)
plt.title("Accuracy per Species by Model")
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()

summary = all_metrics_tuned.groupby("Model")[["Accuracy", "Precision", "Recall", "F1"]].mean().round(3)
summary = summary.sort_values("F1", ascending=False)
display(summary)