# -*- coding: utf-8 -*-
"""TunedXGB.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U8UCfFuLkUZuAwPyoqOV_ZsBAD9a-Uc3
"""

import xgboost as xgb
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score
import pandas as pd
import numpy as np

# Load dataset
df = pd.read_csv("species_biome_env_dataset.csv")

# Biome and species setup
biome_lookup = {
    1: "Tropical Forest", 2: "Temperate Forest", 3: "Boreal Forest",
    4: "Tropical Grassland", 5: "Temperate Grassland", 6: "Desert",
    7: "Shrubland", 8: "Tundra", 9: "Flooded Grassland", 10: "Mangroves",
    11: "Mediterranean", 12: "Montane", 13: "Xeric Shrubland", 14: "Ice and Rock"
}
species_cols = [
    "axolotl", "blue_macaw", "ocelot", "black_iguana", "resplendent_quetzal",
    "coyote", "crested_caracara", "green_turtle", "american_alligator", "asian_elephant"
]
biome_ids = sorted(df["BIOME"].dropna().unique())

# Matrix and metrics storage
compatibility_matrix_xgb_tuned = pd.DataFrame(index=species_cols, columns=[biome_lookup.get(b, f"Biome {b}") for b in biome_ids])
tuned_metrics = []

# Scoring
f1_scorer = make_scorer(f1_score, zero_division=0)

# Grid parameters
param_grid = {
    "max_depth": [3, 6],
    "learning_rate": [0.1, 0.3],
    "n_estimators": [100, 200],
    "subsample": [0.8],
    "colsample_bytree": [0.8]
}

metrics = []

# Loop over species
for species in species_cols:
    print(f"\n Tuning XGBoost for: {species}")
    y = df[species].astype(int)

    env_cols = [col for col in df.columns if col.startswith("BIO")]
    biome_encoded = pd.get_dummies(df["BIOME"], prefix="BIOME")
    X = pd.concat([df[env_cols], biome_encoded], axis=1)
    X = X.apply(pd.to_numeric, errors='coerce').replace([np.inf, -np.inf], np.nan)
    X = X.fillna(X.mean(numeric_only=True))
    y = y.loc[X.index]

    if y.value_counts().min() < 2:
        print(f"Skipping {species} due to insufficient class diversity.")
        continue

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    try:
        X_train, X_test, y_train, y_test = train_test_split(
            X_scaled, y, test_size=0.25, random_state=42, stratify=y
        )
    except ValueError as ve:
        print(f"Skipping {species} — split error: {ve}")
        continue

    # Calculate scale_pos_weight
    pos = sum(y_train == 1)
    neg = sum(y_train == 0)
    spw = neg / pos if pos > 0 else 1

    xgb_base = XGBClassifier(
        use_label_encoder=False,
        eval_metric="logloss",
        random_state=42,
        scale_pos_weight=spw
    )

    grid = GridSearchCV(
        xgb_base,
        param_grid,
        scoring=f1_scorer,
        cv=3,
        n_jobs=-1
    )

    try:
        grid.fit(X_train, y_train)
        best_model = grid.best_estimator_
    except Exception as e:
        print(f" Training failed for {species}: {e}")
        continue

    y_pred = best_model.predict(X_test)
    probas = best_model.predict_proba(X_scaled)[:, 1]

    print(f"Best F1: {f1_score(y_test, y_pred):.3f} | Params: {grid.best_params_}")

    tuned_metrics.append({
        "Species": species,
        "Model": "XGBoost (Tuned)",
        "Best Params": grid.best_params_,
        "Accuracy": accuracy_score(y_test, y_pred),
        "Precision": precision_score(y_test, y_pred, zero_division=0),
        "Recall": recall_score(y_test, y_pred, zero_division=0),
        "F1": f1_score(y_test, y_pred, zero_division=0)
    })

    # Fill compatibility matrix
    df_temp = df.loc[X.index].copy()
    df_temp["pred_prob"] = probas
    biome_avg = df_temp.groupby("BIOME")["pred_prob"].mean()

    for biome_id, prob in biome_avg.items():
        biome_label = biome_lookup.get(biome_id, f"Biome {biome_id}")
        compatibility_matrix_xgb_tuned.loc[species, biome_label] = round(prob, 3)

# Save tuned metrics
tuned_xgb_df = pd.DataFrame(tuned_metrics)
tuned_xgb_df.to_csv("xgb_tuned_metrics.csv", index=False)

# Save new matrix
compatibility_matrix_xgb_tuned = compatibility_matrix_xgb_tuned.fillna("–")
compatibility_matrix_xgb_tuned.to_csv("xgb_tuned_matrix.csv")
display(compatibility_matrix_xgb_tuned)

# Heatmap

import matplotlib.pyplot as plt
import seaborn as sns

# Convert values to float (in case of "–")
heatmap_data = compatibility_matrix_xgb_tuned.replace("–", np.nan).astype(float)

plt.figure(figsize=(12, 6))
sns.heatmap(heatmap_data, annot=True, cmap="YlGnBu", fmt=".2f", cbar_kws={"label": "Predicted Suitability"})
plt.title("Species × Biome Compatibility Heatmap (XGBoost Tuned)")
plt.xlabel("Biome")
plt.ylabel("Species")
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()